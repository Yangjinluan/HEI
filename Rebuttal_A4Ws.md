{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c0cde0-fdfc-4f35-8a03-39f8fbbf2025",
   "metadata": {},
   "source": [
    "**Our contributions:**\n",
    "\n",
    "**(a) Problem view:** a new distribution shift perspective(node's neighbor pattern gap between train and test) to promote node representation learning on heterophilic graphs. **Compared with previous works that aim to design a more effective HGNN backbone, we are the first to reconsider the node representation aggregation from data distribution, thus further integrating with existing SOTA HGNN's backbones to achieve better performance(line214-line246)**. Notably, the data distribution means that **we should compare the structure-related distribution between train and test datasets(Figure 7) on the same dataset rather than directly statistics on the full dataset like many other studies.** \n",
    "\n",
    "**(b) Technique view:** To address our pointed distribution shift, we make a detailed theoretical analysis to explain why previous graph-based invariant learning methods can't work well(Figure 1, line 271-281,line341, line 381). \\textbf{Compared with previous works that generate extra augmented graphs by mask strategy to construct different environments(Figure 1, line 312-340), we utilize the node's inherent neighbor pattern information to infer environments without augmentation.} Then a natural question arises as bold by lines 147,151, **how can we ensure the effectiveness of our proposed graph-based invariant learning methods? Thus, we should provide strict theory evidence for selecting a proper matrix to estimate the node's neighbor pattern from a graph perspective(Section 4.1) and casual invariant learning perspective(Section 4.3)** rather than only from experimental results. A more detailed analysis can be found in the appendix(Figure 5, A.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99cf4e-9d60-4ad1-bf2f-f0a113a247fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50fd7c-429e-4a7f-8928-b5df79191333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3cd028e-5768-40a6-9d15-7ddadd5854b2",
   "metadata": {},
   "source": [
    "**Rebuttal for Reviewer sSKZ**\n",
    "\n",
    "Thanks for your questions, we would like to reclarify the contribution first and then answer your questions.\n",
    "\n",
    "**Q1 More clarification for theoretical analysis**\n",
    "\n",
    "Thanks for your questions. Exactly, we focus on heterophilic graph structure distribution shift and our method belongs to graph-based invariant learning methods like previous works(e.g. EERM[1]), which aim to address the distribution shift. Thus, the theoretical analysis should include the graph perspective and causal invariant learning perspective respectively. The casual invariant learning methods should explore the relationship between input random variables like Figure 5 in the appendix, and exactly we also provide a more detailed analysis in A.2. We will further strengthen this and make it more understandable in the revised paper. And we hope you can reclarify our contribution.\n",
    "\n",
    "**Q2 More clarification for comparison experiments**\n",
    "\n",
    "**(a)Datasets:** As stated in Table 1, we have conducted experiments on commonly used heterophilic small and large-scale datasets, which include one hundred thousand nodes and millions of edges.\n",
    "\n",
    "**(b)Baselines:** The method INL[2] you mentioned is still a work that focuses on backbone design, as stated by our contribution, we focus on reconsidering the node representation aggregation from distribution shift, thus further proposing a framework that can be integrated with existing SOTA HGNN's backbones to achieve better performance. We also provide part of comparison experiments based on your mentioned work to verify the effectiveness of our method further. Moreover, the uploading time of your mentioned paper is later than the submission of KDD this year. We will add these discussions referring to your questions.\n",
    "\n",
    "|  Method(Chameleon)  | Full Test| High Hom Test  | Low Hom Test  |\n",
    "|  :------  | :------:  | :------:  | :------:  | \n",
    "| INL  | 71.84 ± 1.22 | 76.81 ± 1.78| 65.97 ± 3.75  | \n",
    "| INL + HEI(Ours) | 74.74 ± 1.18 |  78.33 ± 1.35 |69.05  ± 3.45 |  \n",
    "\n",
    "|  Method(Squirrel)  | Full Test| High Hom Test  | Low Hom Test  |\n",
    "|  :------  | :------:  | :------:  | :------:  | \n",
    "| INL  | 64.38 ± 0.62 | 74.29 ± 3.85| 54.02 ± 1.54  | \n",
    "| INL + HEI(Ours) | 68.14 ± 0.59 |  77.35 ± 2.81 |58.13 ± 1.58   |\n",
    "\n",
    "|  Method(Actor)  | Full Test| High Hom Test  | Low Hom Test  |\n",
    "|  :------  | :------:  | :------:  | :------:  | \n",
    "| INL  | 38.12 ± 0.36 | 41.67 ± 1.38 |35.11 ± 1.85  | \n",
    "| INL + HEI(Ours) | 39.62 ± 0.56 | 44.14 ± 1.48 |37.14 ± 1.85  |\n",
    "\n",
    "**Q3 More clarification for computational efficiency**\n",
    "\n",
    "Exactly, we have provided complexity analysis in A.1. To further clearly address your concern about computational efficiency on large-scale datasets, we provide efficiency experiments on large-scale datasets referring to [2]. The reported results are the time(seconds) to train the model until converge, we can conclude that the extra time cost can be acceptable compared with the base(backbone itself). \n",
    "\n",
    "|  Method  | Penn94| arxiv-year  | twitch-gamer |\n",
    "|  :------  | :------:  | :------:  | :------:  | \n",
    "| Base   | 22.3 | 7.2| 40.5.  | \n",
    "| Renode | 23.5 | 7.6| 41.2  |  \n",
    "| SR-GNN | 22.9 | 7.4| 41.0  |   \n",
    "| EERM   | 24.0 | 8.0| 41.5.  |  \n",
    "| BAGNN  | 24.8 | 8.6| 42.1 |   \n",
    "| FLOOD  | 24.5 | 8.2| 41.8  | \n",
    "| HEI(ours)| 24.1 | 8.3| 41.9 | \n",
    "\n",
    "[1] Handling distribution shifts on graphs: An invariance perspective. ICLR2022.\n",
    "\n",
    "[2] Discovering Invariant Neighborhood Patterns for Non-Homophilous Graphs. Arxiv 2024.\n",
    "\n",
    "[3] Finding global homophily in graph neural networks when meeting heterophily. ICML2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362d4601-dfc3-48d8-af95-3e3018f52bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37420fb6-f6a7-47de-8740-f47bf2259e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcb613f-07a2-4973-a641-a3422ecc957d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57774a88-5dae-427f-b3b0-74d53efe3a96",
   "metadata": {},
   "source": [
    "**Rebuttal for Reviewer 38Kn**\n",
    "\n",
    "Thanks for your questions, we would like to reclarify the contribution first and then answer your questions.\n",
    "\n",
    "**Q1 The significance of the investigated problem** \n",
    "\n",
    "Thanks for your questions. As we know, heterophilic graphs are composed of nodes with different levels of homophily. Many previous HGNNS works aim to propose more effective Neighbor aggregation mechanisms to select similar neighbors for each node during neighbor aggregation, thus designing better backbones to achieve good performance on heterophily graph datasets. However, as shown in Table 5, their evaluation is only based on the full test nodes neglecting the difference of test nodes with high and low homohily respectively. \n",
    "\n",
    "**(a)From the application view**, take anomaly detection as an example, due to various time factors and the\n",
    "annotation preferences of human experts, the heterophily and homophily can change across training and testing data, this distribution gap will weaken the generalization of the trained model to detect the anomaly class and the normal classes with different levels of node homophily. To avoid the influence of homophily distribution on model predictions, we should train a model that can perform well on test nodes with high homophily and low homophily simultaneously. Thus, apart from full test accuracy, we should also focus on the performance gap between test groups with different levels of homophily, which corresponds to the results of Table 2 and Table 3. Moreover, as stated in lines 786-789, in real-world scenarios, we should consider the effect of data sampling on the model training. That's why we conduct experiments to further verify it's important to address this distribution shift.\n",
    "\n",
    "**(b)From the theory view**, the gap between train and test distribution will influence the evaluation of the model's true performance. A model that can perform well on full test nodes may achieve a huge performance gap between the high homophily test and low homophily test, which further verifies the necessity to address this issue. Moreover, we review the data split in Figure 7 and point out this neglected distribution shift.  Based on the causal invariant learning theory, an ideal model should learn the invariant feature that's independent of the environment-related feature so as to adapt to diverse and complex environments. The unstable environments often cause the gap between train and test data distribution, which is independent of the model backbone and related to data distribution, further influencing the model performance. For node classification tasks, due to the potential unlabeled status of neighbor nodes, we can not know whether the train and test split is reasonable considering the node's neighbor pattern distribution. Thus, apart from directly using a fixed backbone to fit the training data, we should also explore the strategy to optimize the backbone to achieve good performance considering the randomness of sampling, which is also a valuable problem.\n",
    "\n",
    "**Q2 Clarification for experiments** \n",
    "\n",
    "Exactly, the GIN and GCN are not backbones designed for heterophilic graphs. Previous HGNN works compared with GIN and GCN because they mainly focus on HGNN backbone designs, they should further distinguish their proposed backbone from traditional GNN backbone(e.g.GCN). But as stated by contribution, our proposed methods especially focus on the distribution shift on heterophilic graphs and our proposed framework can be integrated with existing SOTA HGNN's backbones to achieve better performance. Thus, the comparison of traditional GCN and GIN is not necessary in our experiments. \n",
    "\n",
    "**Q3 More detailed theoretical analysis** \n",
    "\n",
    "Thanks for your questions. Please see Appendix A.2 to further understand the two conditions you mentioned to re-evaluate our work.\n",
    "\n",
    "**Q4 Code Link** \n",
    "\n",
    "We have provided detailed Implementation Details in A.4. The code can be accessed through the anonymous link https://anonymous.4open.science/r/HEI-AC0D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcf1d6b-8512-4086-a4be-f9499a119036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbee9be-623f-4fa5-a57a-83d87cda001f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f32d7-ef36-4572-a0e6-dbf87904b7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bf96a33-e1f3-4312-bb45-789181a8118e",
   "metadata": {},
   "source": [
    "**Rebuttal for Reviewer A4Ws**\n",
    "\n",
    "Thanks for your questions, we would like to reclarify the contribution first and then answer your questions.\n",
    "\n",
    "**Q1 More clarification for our problem and experiments**\n",
    "\n",
    "As stated by our contribution, **our work is indeed different from previous works.** We aim to compare the structure-related distribution gap between train and test datasets (Figure 7) on heterophilic graphs and explore its effect on node representation learning. **Your mentioned \"numerous existing methods\" just directly statistics on the full dataset and then seek to design effective backbones achieving good performance on homophilic and heterophilic graphs at the same time. In our setting, we focus on the node-level structure-related distribution shift problem on heterophilic graphs, which means there exists a performance gap between test nodes with different levels of homophily. But previous works mainly focus on the performance of the full test nodes without further evaluating under finer-grained divisions.** Exactly, in many real-world applications, we can not know whether the graph is homophilic that's because we can not know the node homophily in advance due to the potential unlabeled status of neighbor nodes. From the perspective of data distribution, the gap between train and test structure-related neighbor pattern distribution will lead to the performance gap between test nodes with different levels of homophily, **this means our work is a novel problem and setting compared with previous works.** In other words, previous HGNN backbones can only ensure the performance on the full test on homophily and heterophilic graph datasets, but it can not address our pointed distribution shift problem even if we adopt the SOTA HGNN backbones as shown in the experiments.\n",
    "\n",
    "**Q2 More clarification to help understand the neighbor pattern.**\n",
    "\n",
    "Exactly, your mentioned geometric position and our adopted similarity are also matrices to evaluate the node's neighbor pattern. **The key exists that the goal we evaluating the neighbor pattern is different from previous works.** As stated by lines(611-167,241-246), previous works aim to explore more effective neighbor aggregation mechanisms to select similar neighbors for each node(**Previous works belong to backbone design works**). However, we utilize the neighbor pattern to infer the node's environments for invariant representation learning(**our work is a framework considering the distribution gap between train and test, that can be integrated with previously designed backbones without difficulty**. Notably, the distribution gap refers to the comparison between train and test rather than directly static on the full graph dataset.)\n",
    "\n",
    "**In other words, we can adapt all neighbor pattern indicators to infer environments as long as they meet the condition we analyze from the causal perspective(Section 4.3 and appendix), that's why we compare different neighbor pattern indicators in Table 4. Moreover, from the results in Table 4, using different neighbor patterns can consistently improve the model performance compared with the backbone itself(Base Results). We also provide a relative explanation to clarify the performance gap using different neighbor pattern indicators in RQ3.**    \n",
    "\n",
    "**Q3 More clarification for evaluation.**\n",
    "\n",
    "Please refer to the contribution stated above to further re-evaluate the experimental results. We not only focus the performance on the full test but concentrate on test results with more fine-granted node groups, which can make the evaluation more reasonable. Simultaneously, the robustness experiments(RQ2) can also further verify the effectiveness of our method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b08be7-7eaf-4119-ae9a-f7f605d4e6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56aee75-21e4-4dab-b11f-ceb34513159c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11cb59fa-fa9e-4ef0-a184-89018cce6a29",
   "metadata": {},
   "source": [
    "**Rebuttal for Reviewer g2D7**\n",
    "\n",
    "Thanks for your questions, we would like to reclarify the contribution first and then answer your questions.\n",
    "\n",
    "**Q1 More clarification for contribution.** \n",
    "\n",
    "**Apart from the contribution stated above, as pointed out by the introduction(161-167) and Related work(241-246), the goal we utilize the similarity to evaluate the neighbor pattern is indeed different from previous works.** Previous works aim to explore more effective neighbor aggregation mechanisms to select similar neighbors for each node(**Previous works belong to backbone design works**). However, we utilize the neighbor pattern to infer the node's environments for invariant representation learning.**Our work is a framework considering the distribution gap between train and test, that can be integrated with previously designed backbones without difficulty. In other words, the framework is our contribution rather than the specific somewhat matrix to design an effective backbone.** As long as we can find indicators that meet the conditions stated in the method, our framework can be integrated with previously designed backbones to further improve model performance from a data distribution perspective. **The experiments in Table 4 can also verify that adopting any similarity-based indicator that meets the conditions we clarify in Methods can achieve better performance than the base(previous SOTA backbone itself).**\n",
    "\n",
    "**Q2 More clarification for computational efficiency**\n",
    "\n",
    "Exactly, we have provided complexity analysis in A.1. To further clearly address your concern about computational efficiency on large-scale datasets, we provide efficiency experiments on large-scale datasets referring to [2]. The reported results are the time(seconds) to train the model until converge, we can conclude that the extra time cost can be acceptable compared with the base(backbone itself). \n",
    "\n",
    "|  Method  | Penn94| arxiv-year  | twitch-gamer |\n",
    "|  :------  | :------:  | :------:  | :------:  | \n",
    "| Base   | 22.3 | 7.2| 40.5.  | \n",
    "| Renode | 23.5 | 7.6| 41.2  |  \n",
    "| SR-GNN | 22.9 | 7.4| 41.0  |   \n",
    "| EERM   | 24.0 | 8.0| 41.5.  |  \n",
    "| BAGNN  | 24.8 | 8.6| 42.1 |   \n",
    "| FLOOD  | 24.5 | 8.2| 41.8  | \n",
    "| HEI(ours)| 24.1 | 8.3| 41.9 | \n",
    "**Q3 More detailed clarification for experiments**\n",
    "\n",
    "Thanks for your questions to help us polish our work. \n",
    "\n",
    "We first clarify our experimental targets to help you understand our work easily. Our proposed framework can be integrated with the previous SOTA HGNN backbone and the similarity is to estimate the neighbor pattern Z. Then the Z is used for the input for the environment classifier to assign the nodes into different environments, which is just our key contribution compared with previous works. The experiments in Table 4 can also verify that adopting any similarity indicators that meet the conditions we clarify in Methods can achieve better performance than the base(previous SOTA backbone itself) **This means the proposed framework is the key rather than the specific somewhat similarity.**\n",
    "\n",
    "Then we provide more detailed experimental details reported in the paper to address your questions.\n",
    "\n",
    "**(a)The used similarity metrics our experiments.** Exactly, all reported results in Table 2 and Table 3 adopt the SimRank as the neighbor pattern indicator. The experiments in Table 4 further answer the question, RQ3, exploring the effect of different similarity matrices. We just use the experiments on small-scall datasets to clarify it more clearly and in lines 859-869, we also provide some theoretical reasons for why adopting the SimRank achieves the best performance. The results adopting different similarity-based matrices on large-scale datasets can be found below， where we use the LINKX as thebackbone.\n",
    "\n",
    "|  Method(Penn94)  | Full Test| High Hom Test  | Low Hom Test  |\n",
    "|  :------  | :------:  | :------:  | :------:  | \n",
    "| HEI(Local_Sim)  | 85.12 ± 0.21| 88.28 ± 0.33 |82.15 ± 0.59 | \n",
    "| HEI(Agg_Sim) |85.21 ± 0.17| 88.29 ± 0.38 |82.22 ± 0.54 |  \n",
    "| HEI(SimRank) | 85.52 ± 0.31| 88.44 ± 0.38 |82.62 ± 0.54 |  \n",
    "\n",
    "|  Method(arxiv-year)  | Full Test| High Hom Test  | Low Hom Test  |\n",
    "|  :------  | :------:  | :------:  | :------:  | \n",
    "| HEI(Local_Sim)  | 54.41 ± 0.21 | 64.23 ± 0.47 | 48.29 ± 0.22 | \n",
    "| HEI(Agg_Sim) | 54.45 ± 0.23 | 64.33 ± 0.49 | 48.33 ± 0.32 |  \n",
    "| HEI(SimRank) | 54.65 ± 0.23 | 64.53 ± 0.63 | 48.63 ± 0.32|\n",
    "\n",
    "|  Method(twitch-gamer)  | Full Test| High Hom Test  | Low Hom Test  |\n",
    "|  :------  | :------:  | :------:  | :------:  | \n",
    "| HEI(Local_Sim)  | 66.18 ± 0.12 | 83.75 ± 0.34 | 48.12 ± 0.47 | \n",
    "| HEI(Agg_Sim) |  66.21 ± 0.15 | 83..85 ± 0.39 | 48.45 ± 0.57 |  \n",
    "| HEI(SimRank) | 66.29 ± 0.15 | 84.03 ± 0.38 | 49.02 ± 0.57 |\n",
    "\n",
    "**(b)Why does the proposed method show better performance on small-scale datasets than on large-scale datasets?** Exactly, we think it's not a proper and fair comparison between the results of small-scale datasets and large-scale datasets, because the scale of test nodes between small datasets and large datasets is indeed different. Compared with the data scale, to further clarify our problem and contribution, the homophily-related data distribution is a more important factor that influences the model performance, that's why we conduct experiments in Figure 3 and Figure 6. But in all settings, our framework can consistently achieve better performance on all small-scale and large-scale datasets compared with previous works.\n",
    "\n",
    "[1] Finding global homophily in graph neural networks when meeting heterophily. ICML2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af6d476-e9b8-457f-b483-b65cdfa1d953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1967a8-5fbc-42fe-a379-bef9f0055aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcaff18-42a8-494f-98d5-2fa94a0075db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b42f4ad-8c88-4e79-83bd-55d2ac0bd900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67809cf9-743a-4e74-a734-c6ffba1e413b",
   "metadata": {},
   "source": [
    "**Rebuttal for Reviewer 8FKd** \n",
    "\n",
    "**Q1 More explanation for the motivation**\n",
    "\n",
    "Thanks for your questions. **First of all, your mentioned works about \"many GNNs can handle such a \"local homophily/heterophily difference\" is indeed different from our method.** Their stated local homophily/heterophily difference is the statistic on the full graph dataset, and they aim to design a backbone that can achieve good performance on the homophilic and heterophilic graphs simultaneously. In contrast, our work focuses on the structure-related distribution shift, especially on heterophilic graphs. The homophily difference in our work exists between the train set and test set from the same dataset rather than different datasets like previous works. And we aim to propose a framework that can be integrated with previous SOTA HGNN to further improve model performance on heterophilic graphs.\n",
    "\n",
    "**Moreover, your mentioned 3 percent is not the distribution gap.** Exactly, Figure 7 reflects how many proportions of nodes are in a certain homophily interval among all train and test nodes. We can easily find that the true distribution gap is more obvious considering the Interval spacing, such as comparing $(0,0.1)$ and $(0.3,1)$. \n",
    "\n",
    "**Furthermore, we can verify the necessity to address our pointed distribution shift from the application view.** Take anomaly detection as an example, due to various time factors and the annotation preferences of human experts, the heterophily and homophily can change across training and testing data, and this distribution gap will weaken the generalization of the trained model to detect the anomaly class and the normal classes with different levels of node homophily. To avoid the influence of homophily distribution on model predictions, we should train a model that can perform well on test nodes with high homophily and low homophily simultaneously. Thus, apart from full test accuracy, we should also focus on the performance gap between test groups with different levels of homophily, which corresponds to the results of Table 2 and Table 3. Moreover, as stated in lines 786-789, in real-world scenarios, we should consider the effect of data sampling on the model training. That's why we conduct experiments to further verify it's important to address this distribution shift.\n",
    "\n",
    "**Q2 More clarification for the connection between similarity-based matrix and neighbor pattern**\n",
    "\n",
    "**The elaboration from Line 432 to Line 452** Exactly, the clusters are formed by the node's feature(raw feature or aggregated feature) rather than the topology(edges). For node classification, the aggregated node embedding comes from its own raw feature and features aggregated from neighbors. It's the aggregated node embeddings that can decide the label, and the node belonging to the same label usually owns the same cluster centroid. Moreover, the neighbor pattern is used to estimate the label relationship between the node and its neighbors. Thus, from the view of the similarity cluster, we can treat the similarity-based matrix as the neighbor pattern indicator.\n",
    "\n",
    "**Q3 More clarification for the experiments**\n",
    "\n",
    "Exactly, as stated by lines 156-158, we truly include latest SOTA heterophilic GNNs' pure performance without any invariant learning solution as a baseline); it can show that current SOTA heterophilic GNNs indeed cannot handle the so-called heterophily shift, and the proposed solution is very general to benefit broad heterophilic GNNs as you said.\n",
    "\n",
    "Moreover, the experiments on homophilic graph datasets can be found in Table 5, the performance gap between the low homophily test and the high homophily test is nearly, which can verify our statement. Or we can re-clarify that the distribution shift on homophilic graph datasets is not obvious compared with heterophilic graphs to help you understand our focused problem easily.\n",
    "\n",
    "\n",
    "**Q4 Other replies to the concepts you mentioned**\n",
    "\n",
    "(a) Line 291: The adjacency matrix of a node is a 0 1 matrix that describes its connected nodes among all nodes.\n",
    "\n",
    "(b) Line 441: we can not understand your questions. We would be glad to address it if you could clarify it more clearly.\n",
    "\n",
    "(c) Lines 559 and 560: it's our writing issues. In causal analysis, the separated random variable should be bold, and others are not. And the X and A should both contain two elements, it's our neglected writing issues.  We will make a more detailed statement and carefully polish the paper in the revised version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b2fefd-d88d-4a28-9c4b-c3fac96567e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dd2396-f809-4afb-ae93-57f335f34065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1a4599-54ba-4e6f-9c16-2c5f58543e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0420e23-eec1-45e2-a77f-369435be70ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f2812d3-bd2e-4d16-ad6d-eebf6b4808bb",
   "metadata": {},
   "source": [
    "**Reply to Reviewer yYCJ**\n",
    "\n",
    "**Q1 The significance of the investigated problem** \n",
    "\n",
    "Thanks for your questions. As we know, heterophilic graphs are composed of nodes with different levels of homophily. Many previous HGNNS works aim to propose more effective Neighbor aggregation mechanisms to select similar neighbors for each node during neighbor aggregation, thus designing better backbones to achieve good performance on heterophily graph datasets. However, as shown in Table 5, their evaluation is only based on the full test nodes neglecting the difference of test nodes with high and low homohily respectively. \n",
    "\n",
    "**From the application view**, take anomaly detection as an example, due to various time factors and the annotation preferences of human experts, the heterophily and homophily can change across training and testing data, and this distribution gap will weaken the generalization of the trained model to detect the anomaly class and the normal classes with different levels of node homophily. To avoid the influence of homophily distribution on model predictions, we should train a model that can perform well on test nodes with high homophily and low homophily simultaneously. Thus, apart from full test accuracy, we should also focus on the performance gap between test groups with different levels of homophily, which corresponds to the results of Table 2 and Table 3. Moreover, as stated in lines 786-789, in real-world scenarios, we should consider the effect of data sampling on the model training. That's why we conduct experiments to further verify it's important to address this distribution shift.\n",
    "\n",
    "**From the theory view**, the gap between train and test distribution will influence the evaluation of the model's true performance. A model that can perform well on full test nodes may achieve a huge performance gap between the high homophily test and low homophily test, which further verifies the necessity to address this issue. Moreover, we review the data split in Figure 7 and point out this neglected distribution shift.  Based on the causal invariant learning theory, an ideal model should learn the invariant feature that's independent of the environment-related feature so as to adapt to diverse and complex environments. The unstable environments often cause the gap between train and test data distribution, which is independent of the model backbone and related to data distribution, further influencing the model performance. For node classification tasks, due to the potential unlabeled status of neighbor nodes, we can not know whether the train and test split is reasonable considering the node's neighbor pattern distribution. Thus, apart from directly using a fixed backbone to fit the training data, we should also explore the strategy to optimize the backbone to achieve good performance considering the randomness of sampling, which is also a valuable problem.\n",
    "\n",
    "**Q2 More explanation for similarity matrix**\n",
    "\n",
    "We first clarify that we don't use three similarity matrices in our framework simultaneously. The theory in 4.1 just verifies that we can use these different matrices to estimate the neighbor pattern z. Then the neighbor pattern can be used for further invariant learning. Exactly,**as stated by the introduction(161-167) and Related work(241-246), the goal we utilize the similarity to evaluate the neighbor pattern is different from previous works. Previous works aim to explore more effective neighbor aggregation mechanisms to select similar neighbors for each node(they belong to backbone design works). But we utilize the neighbor pattern to infer the node's environments for invariant representation learning(it is a framework considering the distribution gap between train and test, that can be integrated with previously designed backbones without difficulty.** In other words, the framework is our contribution rather than the specific somewhat matrix to design an effective backbone. As long as we can find an indicator that meets the conditions stated in the method, our framework can be integrated with previously designed backbones to further improve model performance from a data distribution perspective. **The experiments in Table 4 can also verify that adopting any similarity-based indicator that meets the conditions we clarify in Methods can achieve better performance than the base(previous SOTA backbone itself).**\n",
    "\n",
    "**Q3 Comparison experiments with GIL**\n",
    "\n",
    "Exactly, we have discussed the GIL with our work in Related work(lines 256-259). We focus on node-level OOD generalization on graphs, while GIL focuses on the graph-level OOD problem. Some consistent discussions and statements can be also found in previous works(e.g.EERM[1],FLOOD[2]).\n",
    "\n",
    "[1] Handling distribution shifts on graphs: An invariance perspective. ICLR2022.\n",
    "\n",
    "[2] FLOOD: A flexible invariant learning framework for out-of-distribution generalization on graphs. KDD2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9838fb6a-0704-4f82-b6bc-33fa736a3306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
