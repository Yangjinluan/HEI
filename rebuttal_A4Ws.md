**Our contributions:**

**(a) Problem view:** a new distribution shift perspective(node's neighbor pattern gap between train and test) to promote node representation learning on heterophilic graphs. **Compared with previous works that aim to design a more effective HGNN backbone, we are the first to reconsider the node representation aggregation from data distribution, thus further integrating with existing SOTA HGNN's backbones to achieve better performance(line214-line246)**. Notably, the data distribution means that **we should compare the structure-related distribution between train and test datasets(Figure 7) on the same dataset rather than directly statistics on the full dataset like many other studies.** 

**(b) Technique view:** To address our pointed distribution shift, we make a detailed theoretical analysis to explain why previous graph-based invariant learning methods can't work well(Figure 1, line 271-281,line341, line 381). **Compared with previous works that generate extra augmented graphs by mask strategy to construct different environments(Figure 1, line 312-340), we utilize the node's inherent neighbor pattern information to infer environments without augmentation. Then a natural question arises as bold by lines 147,151, how can we ensure the effectiveness of our proposed graph-based invariant learning methods? Thus, we should provide strict theory evidence for selecting a proper matrix to estimate the node's neighbor pattern from a graph perspective(Section 4.1) and casual invariant learning perspective(Section 4.3)** rather than only from experimental results. A more detailed analysis can be found in the appendix(Figure 5, A.2).



**Rebuttal for Reviewer A4Ws**

Thanks for your questions, we would like to reclarify the contribution first and then answer your questions.

**Q1 More clarification for our problem and experiments**

As stated by our contribution, **our work is indeed different from previous works.** We aim to compare the structure-related distribution gap between train and test datasets (Figure 7) on heterophilic graphs and explore its effect on node representation learning. **Your mentioned "numerous existing methods" just directly statistics on the full dataset and then seek to design effective backbones achieving good performance on homophilic and heterophilic graphs at the same time. In our setting, we focus on the node-level structure-related distribution shift problem on heterophilic graphs, which means there exists a performance gap between test nodes with different levels of homophily. But previous works mainly focus on the performance of the full test nodes without further evaluating under finer-grained divisions.** Exactly, in many real-world applications, we can not know whether the graph is homophilic that's because we can not know the node homophily in advance due to the potential unlabeled status of neighbor nodes. From the perspective of data distribution, the gap between train and test structure-related neighbor pattern distribution will lead to the performance gap between test nodes with different levels of homophily, **this means our work is a novel problem and setting compared with previous works.** In other words, previous HGNN backbones can only ensure the performance on the full test on homophily and heterophilic graph datasets, but it can not address our pointed distribution shift problem even if we adopt the SOTA HGNN backbones as shown in the experiments.

**Q2 More clarification to help understand the neighbor pattern.**

Exactly, your mentioned geometric position and our adopted similarity are also matrices to evaluate the node's neighbor pattern. **The key exists that the goal we evaluating the neighbor pattern is different from previous works.** As stated by lines(611-167,241-246), previous works aim to explore more effective neighbor aggregation mechanisms to select similar neighbors for each node(**Previous works belong to backbone design works**). However, we utilize the neighbor pattern to infer the node's environments for invariant representation learning(**our work is a framework considering the distribution gap between train and test, that can be integrated with previously designed backbones without difficulty**. Notably, the distribution gap refers to the comparison between train and test rather than directly static on the full graph dataset.)

**In other words, we can adapt all neighbor pattern indicators to infer environments as long as they meet the condition we analyze from the causal perspective(Section 4.3 and appendix), that's why we compare different neighbor pattern indicators in Table 4. Moreover, from the results in Table 4, using different neighbor patterns can consistently improve the model performance compared with the backbone itself(Base Results). We also provide a relative explanation to clarify the performance gap using different neighbor pattern indicators in RQ3.**    

**Q3 More clarification for evaluation.**

Please refer to the contribution stated above to further re-evaluate the experimental results. We not only focus the performance on the full test but concentrate on test results with more fine-granted node groups, which can make the evaluation more reasonable. Simultaneously, the robustness experiments(RQ2) can also further verify the effectiveness of our method.